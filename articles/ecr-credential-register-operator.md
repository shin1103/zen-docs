---
title: "Amazon ECRã«ä¿å­˜ã•ã‚ŒãŸã‚¤ãƒ¡ãƒ¼ã‚¸ã§DockerOperatorã‚’å‹•ã‹ã™"
emoji: "ðŸ˜º"
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: ['airflow', 'aws', 'ecr', 'python', 'docker']
published: true
---
# æ¦‚è¦
Airflowã®DockerOperatorã§AWS ECRã‚’ã‚½ãƒ¼ã‚¹ãƒªãƒã‚¸ãƒˆãƒªã¨ã—ãŸéš›ã¯å˜ç´”ã«ãƒªãƒã‚¸ãƒˆãƒªã‚’æŒ‡å®šã™ã‚‹ã ã‘ã§ã¯ã†ã¾ãè¡Œã‹ãªã‹ã£ãŸã®ã§ã€ãã®è§£æ±ºç­–ã‚’è¨˜è¼‰ã—ã¾ã—ãŸã€‚

# æ¤œè¨Žäº‹é …
AWS ECRã‚’åˆ©ç”¨ã™ã‚‹éš›ã«ã¯èªè¨¼æƒ…å ±ã‚’æ¸¡ã—ã¾ã™ãŒã€ä»¥ä¸‹ã®åˆ¶ç´„ãŒã‚ã‚Šæ¸¡ã—æ–¹ã«è‹¦åŠ´ã—ã¾ã—ãŸã€‚
* ECRã®èªè¨¼æƒ…å ±ã¯12æ™‚é–“ã§èªè¨¼æƒ…å ±ãŒå¤‰æ›´ã•ã‚Œã‚‹ã®ã§ã€äº‹å‰ã«Airflowã®Connectionsã«ä¿å­˜ã—ã¦ã‚‚ã€12æ™‚é–“ãŒçµŒéŽã™ã‚‹ã¨èªè¨¼ã§ããªããªã‚‹
* DockerOperatorã¯å¼•æ•°ã«ãƒ¦ãƒ¼ã‚¶ãƒ»ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å–ã£ã¦ã„ãªã„

# è§£æ±ºæ–¹æ³•
ç§ãŒæŽ¢ã—ãŸé™ã‚Šã§ã¯æ—¢å­˜ã®Operatorã‚„Hookã§ã¯Airflowã®Connectionsã«æƒ…å ±ã‚’æ›¸ãè¾¼ã‚€æ©Ÿèƒ½ãŒæä¾›ã•ã‚Œã¦ãŠã‚‰ãšã€é€”æ–¹ã«æš®ã‚Œã¦ã„ãŸã¨ã“ã‚ä»¥ä¸‹ã®ã‚µã‚¤ãƒˆã‚’ç™ºè¦‹ã—ã¾ã—ãŸã€‚
https://www.lucidchart.com/techblog/2019/03/22/using-apache-airflows-docker-operator-with-amazons-container-repository/

ä¸Šè¨˜ã‚µã‚¤ãƒˆã§ã¯ã€Airflow Cliã‚’å®šæœŸçš„ãªãƒãƒƒãƒã§å‹•ã‹ã—ã¦ã€Airflow Connectionsã‚’æœ€æ–°åŒ–ã™ã‚‹ã‚‚ã®ã§ã™ãŒã€åˆ¥é€”å®šæœŸçš„ãªãƒãƒƒãƒã‚’å‹•ã‹ã™ä»•çµ„ã¿ã‚’ç®¡ç†ã—ãŸããªã‹ã£ãŸã®ã§ã€DockerOperatorã‚’å‹•ã‹ã™å‰ã«Airflow Connectionsã‚’æœ€æ–°åŒ–ã™ã‚‹æ–¹æ³•ã‚’å–ã‚Šã¾ã—ãŸã€‚
ï¼ˆä»Šè€ƒãˆã‚Œã°ã€Airlfowã®PythonOperatorã§å®šæœŸå®Ÿè¡Œã™ã‚Œã°ã‚ˆã‹ã£ãŸã‹ã‚‚ï¼‰

å…·ä½“çš„ã«ã¯Airflow Connectionsã‚’æœ€æ–°åŒ–ã™ã‚‹Custom Operatorã‚’ä½œæˆã—ã€ãƒãƒ¼ãƒ ã®ãƒ«ãƒ¼ãƒ«ã¨ã—ã¦DockerOperatorã®å‘¼ã³å‡ºã—å‰ã«Custom Operatorã‚’å‘¼ã³å‡ºã—ã¦Airflow Connectionsã‚’æœ€æ–°åŒ–ã™ã‚‹æ–¹æ³•ã‚’å–ã‚Šã¾ã—ãŸã€‚
ï¼ˆã“ã‚Œã‚‚ä»Šè€ƒãˆã‚Œã°ã€DockerOperatorã‚’ç¶™æ‰¿ã—ãŸCustom Operatorã‚’ä½œæˆã—ã¦ã€é€éŽçš„ã«Airflow Connectionsã‚’æœ€æ–°åŒ–ã™ã‚‹æ–¹æ³•ã‚’ã‚ã‚Šã ã£ãŸã‹ã‚‚ï¼‰

æœ€çµ‚çš„ã«ä½œæˆã—ãŸCustom Operatorã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚
gistã«ã‚‚åŒã˜ã‚‚ã®ã‚’å…¬é–‹ã—ã¦ã¾ã™ã€‚
https://gist.github.com/shin1103/40e405aa5e8925b59b16d2ab110a3a70

```python
import traceback
from typing import TYPE_CHECKING, Any, List, Optional

from airflow.exceptions import AirflowException
from airflow.models import BaseOperator

if TYPE_CHECKING:
    from airflow.utils.context import Context


class EcrCredentialRegisterOperator(BaseOperator):
    """ register ECR credential to Airflow connections.
    """

    def __init__(self, *, conn_id_name: str, region_name: str, register_ids: List[str], **kwargs,) -> None:
        """ Constructor. conn_id_name, region_name, registry_ids, task_id(this is BaseOperator' arg) is mandatory.

        Args:
            conn_id_name (str): connection id name to register Airflow connections
            region_name (str): ECR's region name
            registry_ids List[str]: AWS accountID(12-figure number). The argument is of type list, but the list is assumed to have a single element.
        """

        super().__init__(**kwargs)
        self.conn_id_name = conn_id_name
        self.region_name = region_name
        self.registry_ids = register_ids

    def __set_ecr_credential_to_airflow(self) -> None:
        """ register ECR credential to Airflow connections.
            this methond refer the site below. In this site, some commandline options is obsolate, I edited some options.
            https://www.lucidchart.com/techblog/2019/03/22/using-apache-airflows-docker-operator-with-amazons-container-repository/
        """

        import base64
        import subprocess

        import boto3

        # Get ECR Credentials
        ecr = boto3.client('ecr', region_name=self.region_name)
        response = ecr.get_authorization_token(registryIds=self.registry_ids)
        username, password = base64.b64decode(
            response['authorizationData'][0]['authorizationToken']
        ).decode('UTF-8').split(':')
        registry_url = response['authorizationData'][0]['proxyEndpoint']

        # Delete existing docker connection
        airflow_del_cmd = 'airflow connections delete {}'.format(
            self.conn_id_name)
        process = subprocess.Popen(
            airflow_del_cmd.split(), stdout=subprocess.PIPE)
        del_output, del_error = process.communicate()

        # Add existing docker connection
        airflow_add_cmd = 'airflow connections add --conn-type docker --conn-host {} --conn-login {} --conn-password {} {}'.format(
            registry_url, username, password, self.conn_id_name)
        process = subprocess.Popen(
            airflow_add_cmd.split(), stdout=subprocess.PIPE)
        add_output, add_error = process.communicate()

    def execute(self, context: 'Context') -> Optional[List[Any]]:
        """ Override BaseOperator
        """

        try:
            self.__set_ecr_credential_to_airflow()
        except Exception as e:
            print(traceback.format_exc())
            raise AirflowException(
                'Fail to register ECR credential to Airflow connections.') from e
```